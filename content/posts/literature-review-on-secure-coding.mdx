---
title: "Literature Review Of Secure Coding"
description: "As humanity progresses through the digital age, the need for secure software becomes more and more in demand. However, security is just one concern among many for a software project's team to consider during development. Through the use of secure coding techniques, programmers can be taught to minimise the accidental intrusion of harmful security vulnerabilities. Effectively, this results in the overall reduction of invested time and money, reducing the likelihood of successful attacks on the system, and the need for additional patches or security features post-development. Harmful worms that exploit these security weaknesses in software have been estimated to produce hundreds of millions of dollars in damages, with the potential for even worse case scenarios. This review has found that secure coding literature agrees on a number of best practices, specifically regarding memory management and data validation, to avoid accidentally introducing security vulnerabilities into software."
author: "Jason Vlajankov"
date: 2022-09-10
tags: ["softwareengineering", "securecoding"]
---

# Introduction

As humanity progresses through the information age, the focus on digital technology and its applications increase. These tools now play a large part in how cultures, economies and societies operate -- facilitated through the internet via billions of network requests/responses everyday. Whether banking, searching, messaging, or virtually anything else, software is instrumental in how these applications can operate. Given how much network-enabled software pervades our day-to-day lives, the discussion of security for these tools naturally surfaces.

Allen _et al_. (<a href="#citeproc_bib_item_1">Allen et al. 2010</a>) argues that security has become a pressing issue in software, stating that the security deficits and vulnerabilities have grown significantly over the years.  Building on this, Viega and McGraw (<a href="#citeproc_bib_item_16">Viega and McGraw 2001</a>), contend that security is just one factor to consider when developing software. It is coupled with a number of other necessary concerns in software development such as time-to-market, reusability, and ease of use, each with their own relative costs. Essentially, it becomes a question of risk management -- which security risks are likely to have the largest impact and are worth investing resources in? These risks are a consequence of security vulnerabilities[^fn:1] that transpire during development as a result of adherence to poor software design (or lack of adherence to good software design). The impact of such risks are totally dependent on the type of vulnerability, the type of information it may expose, and the maliciousness of the exploit.

For example, the Morris Worm incident; a self-replicating computer virus that infected several thousands of computers, disrupting service for several days, but fortunately doing no direct damage (<a href="#citeproc_bib_item_3">Denning 1991</a>). The New York Times publicised (<a href="#citeproc_bib_item_11">Markoff 1988</a>) that the author of the worm was a Cornell graduate student who made a mistake in the design of his software. Despite the lack of maliciousness in the incident, the consequential response was great; a new organisation was formed by DARPA[^fn:2] named the "Computer Emergency Response Team" (CERT) (<a href="#citeproc_bib_item_12">Office of Assistant Secretary of Defense (Public Affairs), Washington, D.C. - 20301 n.d.</a>). While initially constructed to response to incidents such as these worms, CERT has now expanded to a range of other cyber security areas, including secure coding (<a href="#citeproc_bib_item_15">“The CERT Division | Software Engineering Institute” n.d.</a>), which is the focus of this literature review.

Secure coding is the practice of minimising unintentional security vulnerabilities when developing (<a href="#citeproc_bib_item_16">Viega and McGraw 2001</a>). It is a preventative practice, rather than reactive, as it aims to introduce software that is fundamentally secure instead of introducing security features or patches post-vulnerability to cover for poor design. Ideally, this leads to software that is resistant to compromise from third party "black hat hackers"&nbsp;[^fn:3], because given the online, interconnected state of the world, the likelihood of software being attacked is very high. While there are secure coding techniques, there are additionally a number of practices that emphasise secure coding; these could include code review, developer training, adhering to coding standards, and others illustrated by (<a href="#citeproc_bib_item_8">Khan et al. 2022</a>).


## Key Terminology

This section describes the terminology that will be used throughout the literature review:

-   **"Security Vulnerability"** is any fault that weakens the security of the system. For the nature of this paper, this also refers to software vulnerabilities.
-   **"Attack"** is any act that is _intended_ to be malicious towards a system. They typically involve an using an exploit.
-   **"Exploit"** is any technique that takes advantage of a vulnerability in the system, such that it is exposed for (typically) malicious purposes.
-   **"Validation"** is a process in which the system discovers whether the given data is as expected.
-   **"Allocating Memory"** is a process in which the program sets a piece of computer memory to contain a set value, either until the program exits or the memory is "freed".


### Structure

This literature review aims to compile the common secure coding practices and concepts as described in literature, and to provide additional insight into these techniques. It will be structured as follows: An introduction into the background of secure coding, why the practice has surfaced and its effectiveness as a developer tool; An overview of the type of and selection processes of the literature referenced in the review; The literature review itself, highlighting secure coding practices, and how major security vulnerabilities are analysed and addressed through secure coding, along with current day best practices; a Discussion of this literature, providing critical analysis of advantages and disadvantages referenced from the literature; and a Conclusion summarising the reviewed material, their findings and suggestions given this analysis.


## Overview

Literature in this review is organised into two distinct categories. The first including literature relevant to addressing lack of focus towards security in the development life cycle; secure by design practices, practice sthat emphasise secure coding, and security as a relative cost of doing business in risk management.
The second category entails literature relevant to software security planning and implementation as it relates to the technical practice of secure coding; detailing specific security vulnerabilities and exploits, and compiling techniques and best practices so that these issues do not resurface. Much of the literature in secure coding relates to Java, C and C++, as these continue to be popular languages today, and persist large legacy code bases (<a href="#citeproc_bib_item_14">Seacord 2013</a>). References are made to literature from a number of highly respected authors and organisations that are often cited based on their relevance to software security in industry and research.


## Literature Review

Khan _et al_. (<a href="#citeproc_bib_item_8">Khan et al. 2022</a>) concludes from their literature review of SSD[^fn:4] that security is not an afterthought to be considered post-development; this is supremely inefficient, and negatively affects software projects outcomes. Instead, they contend these considerations should be adopted early in the SDLC[^fn:5]. One consideration for SSD they prescribe are secure coding practices; some of which are code reviews, training to software developers, static code analysis, and applying secure coding standards such as CERT -- which will be referenced and expanded upon in this review.

Memory manipulation of strings are the most common area where security vulnerabilities can occur, and much of the literature contains content that explicitly focus on this; detailing how to handle them safely to avoid creating security vulnerabilities (<a href="#citeproc_bib_item_14">Seacord 2013</a>),(<a href="#citeproc_bib_item_9">LeBlanc and Howard 2002</a>),(<a href="#citeproc_bib_item_13">Seacord 2009</a>).

Buffer overflows[^fn:6] can occur in many languages, but are more likely to occur in languages that feature low level memory management of data types. Many viruses end up exploiting this (see Morris worm (<a href="#citeproc_bib_item_3">Denning 1991</a>), or Blaster worm (<a href="#citeproc_bib_item_2">Bailey et al. 2005</a>)) and are one of the most well known avenues of attack that tends to be easily and accidentally introduced.
Howard and LeBlanc (<a href="#citeproc_bib_item_9">LeBlanc and Howard 2002</a>) describe this type of vulnerability as especially pertinent in C and C++ languages, as it gives programmers ways to consistently "shoot themselves in the foot" with the amount of freedom they are given, resulting in software with poor memory management. Coupled with a no safe string-handling and programmers' general lack of awareness on the consequences, the resulting software can easily become insecure. Specifically, a buffer overflow condition occurs when an application doesn't perform adequate bounds checking and writes more bytes to a buffer than there is room. A hacker may cause this buffer to "overflow" in such a way that it executes additional, unauthorised commands in other memory locations.

Seacord (<a href="#citeproc_bib_item_14">Seacord 2013</a>) describes how these types of attacks can have disastrous effects using the Blaster worm incident -- at its peak the worm was was infecting over 100,000 systems per hour. It propagated via TCP/IP; exploiting a security vulnerability in the DCOM RPC[^fn:7] that allowed hackers to run code on an affected system, and resulted in an estimated $525 million of damages, potentially more if it happened to be more malicious.
A seemingly innocuous snippet of code was responsible for this:

<a id="code-snippet--buffer-overflow-1"></a>
```C
while( *pwszTemp != L '\\' )
    *pwszServerName++ = *pwszTemp++
    // ...
```
<div class="src-block-caption">
  <span class="src-block-number"><a href="#code-snippet--buffer-overflow-1">Code Snippet 1</a>:</span>
  RPC buffer overflow vulnerability
</div>

The while loop shown in listing [1](#code-snippet--buffer-overflow-1), although seemingly innocuous, is not adequately bounded. This results in the security vulnerability that was exploited by Blaster worm. Seacord (<a href="#citeproc_bib_item_14">Seacord 2013</a>) goes on to describe how a second condition inside this while loop could have easily bound the process, preventing this vulnerability from existing.

Building upon this idea, Howard and Leblanc (<a href="#citeproc_bib_item_9">LeBlanc and Howard 2002</a>) go on to contend that all inputs for functions should be considered potentially unsafe.

<a id="code-snippet--buffer-overflow-2"></a>
```C
void Function(const char* input)
{
    char overflow[255];

    sprintf(overflow, "Prefix %s suffix\n", input);
    // ...
}
```
<div class="src-block-caption">
  <span class="src-block-number"><a href="#code-snippet--buffer-overflow-2">Code Snippet 2</a>:</span>
  Insecure function
</div>

Referring to listing [2](#code-snippet--buffer-overflow-2), the hacker exploits the function using `sprintf`, resulting in the invalid `input` string sending output to the string `overflow`, consequentially overflowing the buffer and giving the them an opportunity to execute unauthorised commands in other memory locations. By validating this string structure `const char* msg` beforehand, the software can avoid this vulnerability .

In (<a href="#citeproc_bib_item_13">Seacord 2009</a>), Seacord goes on to contend that as a standard of good memory management, programmers should be encouraged to perform both the allocation and freeing of memory within the same code modules, at the same levels of abstraction. This advised standard included the use of memory functions described in the C99 standard&nbsp;[^fn:8], functions like `malloc`, or `calloc`. This standard helps prevents potential vulnerabilities that may come about as a result of defects like writing or accessing freed memory, or freeing memory that has already been released.

Java is another popular language that, relative to aforementioned options like C and C++, is not as susceptible to common security vulnerabilities exposed during memory management, which may make it more suitable to develop secure systems with. Graff and Wyk (<a href="#citeproc_bib_item_7">Graff and Wyk 2003</a>) support this idea, stating a defence for this vulnerability is to instead use Java, which is safe against this by default. Alternatively, similarly to Seacord's previous recommendation, they also suggest to generally avoid reading unsafe inputs into fixed-length buffers. Although, without a good understanding of Java secure coding, systems built using it may still be exposed to a number of other vulnerabilities.

Long _et al_. (<a href="#citeproc_bib_item_10">Long et al. 2011</a>) contends that, although many typical vulnerabilities do not exist, some may still be effective against Java -- for example, vulnerabilities relating to the program's deployment. If a software is deployed via a system that is not sufficiently secure, for example with an unsafe security policy, it may be at risk of exposing itself to an injection attack. This type of attack aims to poison the data that is received by the target program's software component(s), potentially resulting in it executing with it, without validation. This execution could include a call to an engine or interpreter, effectively allowing the hacker to execute their own commands or special actions, due to this poisoned data. This sort of vulnerability is critically different to a buffer overflow, as the execution of the unauthorised commands is reliant on the software component's ability to interpret them in the appropriate way.

An analysis on secure coding completed by Gasiba _et al_. (<a href="#citeproc_bib_item_4">Espinha Gasiba et al. 2020a</a>) argued that while there is a motivation from developers to comply with secure coding guidelines, they tend to overestimate their secure coding skills and would benefit from additional secure coding campaigns.

The literature goes on to describe solutions for other types of vulnerabilities that cannot be covered at length in this review.


## Discussion

Graff and Wyk (<a href="#citeproc_bib_item_7">Graff and Wyk 2003</a>) argue that a defence of the buffer overflow attack is to "Code in a language (such as Java) that rules out buffer overflows by design" However, this is not always a legitimate defence for this attack, as it instead leans on avoiding the security vulnerability, rather than addressing it programmatically. It may be the case that understanding and patching the vulnerability using a secure coding method would benefit the project more. In other words, Java may be the preferred choice for building systems that hinge on security as one of the fundamental aspects of its function, as you are guaranteed to not accidentally introduce these types of vulnerabilities. If the opposite were true, all systems would be built in Java -- and that is not the case. Essentially, the system or the development of it may actually benefit other aspects because of the robust and lightweight nature of a language like C or C++ , thus discarding other options without suggesting a comprehensive review of the project's requirements is incorrect.

If building or adapting a legacy system the ground up today, adopting more modern programming languages that are both secure and robust would be the ideal solution. Rust (or Go) may be a prime example of such a language, however despite the long-term development benefits, they seem to be currently struggling with adoption (<a href="#citeproc_bib_item_6">Fulton et al. 2021</a>), citing issues like a steep learning curve. This learning curve, similarly to suggestions made by Gasiba _et al_. in (<a href="#citeproc_bib_item_5">Espinha Gasiba et al. 2020b</a>), could be alleviated by conducting secure coding workshops, or senior programmers and managers emphasising their use in industry.


## Conclusion

This content of this review clearly demonstrates the need for secure coding in the development of software, especially for the development of critical infrastructure. Even a small mistake in the code of a driver can result in the inclusion of accidental security vulnerabilities that may end in thousands of infected computers, loss time and frustration, and potentially millions of dollars in damages.

The review has specified and demonstrated reasonable defences of such vulnerabilities in software, and the advantages/disadvantages of such. This review suggests that software developers, senior developers, and managers do their due diligence in encouraging the use of secure coding literature and secure coding techniques in industry. Conducting regular code reviews with the development team, and correctly applying respected secure coding standards, such as CERT's mentioned in this review, would help reduce risk vectors present for a hacker to penetrate the system -- effectively making it more secure.

## References

<div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Allen, Julia, Sean Barnum, Robert Ellison, Gary McGraw, and Nancy Mead. 2010. “Software Security Engineering: A Guide for Project Managers” 23 (March).</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>Bailey, M., E. Cooke, F. Jahanian, and D. Watson. 2005. “The Blaster Worm: Then and Now.” <i>Ieee Security &#38; Privacy</i> 3 (4): 26–31. <a href="https://doi.org/10.1109/MSP.2005.106">https://doi.org/10.1109/MSP.2005.106</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>Denning, Peter J. 1991. “The Internet Worm.” In <i>Computers under Attack: Intruders, Worms, and Viruses</i>, edited by Peter J. Denning, 193–200. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/102616.102629">https://doi.org/10.1145/102616.102629</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>Espinha Gasiba, Tiago, Ulrike Lechner, Maria Pinto-Albuquerque, and Daniel Mendez Fernandez. 2020a. “Awareness of Secure Coding Guidelines in the Industry - A First Data Analysis.” In <i>2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)</i>, 345–52. <a href="https://doi.org/10.1109/TrustCom50675.2020.00055">https://doi.org/10.1109/TrustCom50675.2020.00055</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>———. 2020b. “Awareness of Secure Coding Guidelines in the Industry - A First Data Analysis.” In <i>2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)</i>, 345–52. <a href="https://doi.org/10.1109/TrustCom50675.2020.00055">https://doi.org/10.1109/TrustCom50675.2020.00055</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>Fulton, Kelsey R., Anna Chan, Daniel Votipka, Michael Hicks, and Michelle L. Mazurek. 2021. “Benefits and Drawbacks of Adopting a Secure Programming Language: Rust as a Case Study.” In <i>Seventeenth Symposium on Usable Privacy and Security (SOUPS 2021)</i>, 597–616. <a href="https://www.usenix.org/conference/soups2021/presentation/fulton">https://www.usenix.org/conference/soups2021/presentation/fulton</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>Graff, Mark, and Kenneth R. Van Wyk. 2003. <i>Secure Coding: Principles and Practices</i>. “O’Reilly Media, Inc.”</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>Khan, Rafiq Ahmad, Siffat Ullah Khan, Habib Ullah Khan, and Muhammad Ilyas. 2022. “Systematic Literature Review on Security Risks and Its Practices in Secure Software Development.” <i>Ieee Access</i> 10: 5456–81. <a href="https://doi.org/10.1109/ACCESS.2022.3140181">https://doi.org/10.1109/ACCESS.2022.3140181</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_9"></a>LeBlanc, David, and Michael Howard. 2002. <i>Writing Secure Code</i>. Redmond, Wash: Microsoft Press US.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_10"></a>Long, Fred, Dhruv Mohindra, Robert C. Seacord, Dean F. Sutherland, and David Svoboda. 2011. <i>The CERT Oracle Secure Coding Standard for Java</i>. Addison-Wesley Professional.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_11"></a>Markoff, John. 1988. “Author of Computer ’Virus’ Is Son Of N.S.A. Expert on Data Security.” <i>The New York Times</i>, November. <a href="https://www.nytimes.com/1988/11/05/us/author-of-computer-virus-is-son-of-nsa-expert-on-data-security.html">https://www.nytimes.com/1988/11/05/us/author-of-computer-virus-is-son-of-nsa-expert-on-data-security.html</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_12"></a>Office of Assistant Secretary of Defense (Public Affairs), Washington, D.C. - 20301. n.d. “DARPA Establishes Computer Emergency Response Team.” Accessed August 24, 2022. <a href="https://www.esd.whs.mil/Portals/54/Documents/FOID/Reading%20Room/DARPA/20-F-1335_Final_Production_CERT_CC_1988.pdf">https://www.esd.whs.mil/Portals/54/Documents/FOID/Reading%20Room/DARPA/20-F-1335_Final_Production_CERT_CC_1988.pdf</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_13"></a>Seacord, Robert C. 2009. <i>The CERT C Secure Coding Standard</i>. SEI Series in Software Engineering. Upper Saddle River, N.J: Addison-Wesley.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_14"></a>———. 2013. <i>Secure Coding in C and C++</i>. 2nd ed. SEI Series in Software Engineering. Upper Saddle River, NJ: Addison-Wesley.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_15"></a>“The CERT Division | Software Engineering Institute.” n.d. Accessed August 27, 2022. <a href="https://www.sei.cmu.edu/about/divisions/cert/index.cfm">https://www.sei.cmu.edu/about/divisions/cert/index.cfm</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_16"></a>Viega, John, and Gary R. McGraw. 2001. <i>Building Secure Software: How to Avoid Security Problems the Right Way, Portable Documents</i>. Pearson Education.</div>
</div>

[^fn:1]: Synonymous with bugs, faults, software vulnerabilities.
[^fn:2]: Defense Advanced Research Projects Agency
[^fn:3]: Cyber criminals that exploit security vulnerabilities maliciously.
[^fn:4]: Secure Software Development
[^fn:5]: Software Development Life Cycle is the practice that businesses adopt when managing large software projects to help maintain better control of the timeline and schedule.
[^fn:6]: Also occasionally referred to as a "buffer overrun", or "overrun hole".
[^fn:7]: Windows Distributed Component Object Model (DCOM) Remote Procedure Call (RPC) interface
[^fn:8]: A specification of the past version of the C programming language that was extended with new features and libraries.
